{"title":"Normal Distribution (Examples 7.24 & 7.25)","markdown":{"headingText":"Normal Distribution (Examples 7.24 & 7.25)","containsRefs":false,"markdown":"\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo=TRUE, eval=TRUE, comment=NA)\nlibrary(webexercises)\nlibrary(PASWR2)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(ggplot2)\nlibrary(tidyverse)\n```\n\n<!--MLE for sigma^2-->\n\nSuppose $\\left\\{X_1,X_2,\\dots,X_n\\right\\}$ is a random sample from a $N\\left(\\mu, \\sigma\\right)$ distribution, where $\\mu$ is **known**. Find the maximum likelihood estimator of $\\sigma^2$, by hand. The questions below should help you understand the steps required to find the *MLE*.\n\n:::{.question}\n::::{.question-header}\nTask\n::::\n::::{.question-container}\n```{r, echo=FALSE}\nopts1 <- sample(c(answer = \"$f(x)=\\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}}\\\\exp\\\\left(-\\\\frac{(x-\\\\mu)^2}{2\\\\sigma^2}\\\\right)$\",\n                  \"$f(x)=\\\\frac{(\\\\sigma^2)^\\\\mu x^{\\\\mu-1}\\\\exp(-\\\\sigma^2x)}{\\\\Gamma(\\\\mu)}$\",\n                  \"$f(x)=\\\\mu\\\\exp(-\\\\mu x)$\",\n                  \"$f(x)=\\\\frac{\\\\mu}{2\\\\pi\\\\sigma^2}\\\\exp\\\\left(-\\\\frac{(x-\\\\mu)^2}{\\\\sigma^2}\\\\right)$\"))\n```\n\n:::: {.webex-check}\n**What is the probability density function (pdf) of a random variable $X\\sim{N}\\left(\\mu,\\sigma\\right)$**\n`r longmcq(opts1)`\n::::\n\n`r hide(\"Solution\")`\nThe pdf of a random variable $X\\sim{N}\\left(\\mu,\\sigma\\right)$ is given by,\n\n$$\nf(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,-\\infty<x<\\infty.\n$$\nSee the [Probability Formula Sheet](https://gla-my.sharepoint.com/:b:/g/personal/mitchum_bock_glasgow_ac_uk/EYMw7JaKJPhJqtx7U2y8014BpMoLnJ1iyb-ELxDb8hvGYg?e=BQm80L){target=\"_blank\"}.\n\n`r unhide()`\n::::\n:::\n\n:::{.question}\n::::{.question-header}\nTask\n::::\n::::{.question-container}\n```{r, echo=FALSE}\nopts2 <- sample(c(answer = \"$L(\\\\sigma^2|\\\\mathbb{x})=\\\\prod_{i=1}^n\\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}}\\\\exp\\\\left(-\\\\frac{(x_i-\\\\mu)^2}{2\\\\sigma^2}\\\\right)$\",\n                  \"$L(\\\\sigma^2|\\\\mathbb{x})=\\\\prod_{i=1}^n\\\\frac{(\\\\sigma^2)^\\\\mu x_i^{\\\\mu-1}\\\\exp(-\\\\sigma^2x_i)}{\\\\Gamma(\\\\mu)}$\",\n                  \"$L(\\\\sigma^2|\\\\mathbb{x})=\\\\prod_{i=1}^n\\\\mu\\\\exp(-\\\\mu x_i)$\",\n                  \"$L(\\\\sigma^2|\\\\mathbb{x})=\\\\prod_{i=1}^n\\\\frac{\\\\mu}{2\\\\pi\\\\sigma^2}\\\\exp\\\\left(-\\\\frac{(x_i-\\\\mu)^2}{\\\\sigma^2}\\\\right)$\"))\n```\n::::{.webex-check}\n**What is the likelihood function of a random sample of $n$, normally distributed random variables with mean $\\mu$ and standard deviation $\\sigma$?**\n`r longmcq(opts2)`\n::::\n\n`r hide(\"Solution\")`\nThe likelihood of $n$ random variables is given by the product of the $n$ probability density functions. In this case, the likelihood function of $n$ normally distributed random variables is given by,\n\n$$\n\\begin{align}\nL(\\sigma^2|\\mathbb{x})&=\\prod_{i=1}^nf(x_i)\\\\\n&=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\n\\end{align}\n$$ {#eq-normallike}\n`r unhide()`\n::::\n:::\n\n:::{.question}\n::::{.question-header}\nTask\n::::\n::::{.question-container}\n```{r, echo=FALSE}\nopts3 <- sample(c(answer = \"$\\\\ln L(\\\\sigma^2|\\\\mathbb{x})=-\\\\frac{n}{2}\\\\ln(2\\\\pi)-\\\\frac{n}{2}\\\\ln(\\\\sigma^2)-\\\\frac{\\\\sum_{i=1}^n(x_i-\\\\mu)^2}{2\\\\sigma^2}$\",\n                  \"$\\\\ln L(\\\\sigma^2|\\\\mathbb{x})=-\\\\frac{n}{2}\\\\ln(2\\\\pi)-\\\\frac{n}{2}\\\\ln(\\\\sigma^2)-\\\\exp\\\\left(\\\\frac{\\\\sum_{i=1}^n(x_i-\\\\mu)^2}{2\\\\sigma^2}\\\\right)$\",\n                  \"$\\\\ln L(\\\\sigma^2|\\\\mathbb{x})=\\\\prod_{i=1}^n\\\\ln\\\\left[(2\\\\pi\\\\sigma^2)^{-\\\\frac{1}{2}}\\\\right]+\\\\sum_{i=1}^n\\\\left(-\\\\frac{(x_i-\\\\mu)^2}{2\\\\sigma^2}\\\\right)$\",\n                  \"$\\\\ln L(\\\\sigma^2|\\\\mathbb{x})=\\\\ln\\\\left[\\\\sum_{i=1}^n\\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}}\\\\right]+\\\\ln\\\\left[\\\\sum_{i=1}^n\\\\exp\\\\left(-\\\\frac{(x_i-\\\\mu)^2}{2\\\\sigma^2}\\\\right)\\\\right]$\"))\n```\n::::{.webex-check}\n**By taking the natural logarithm of the likelihood function, what is the log-likelihood function of $n$, normally distributed random variables with mean $\\mu$ and standard deviation $\\sigma$?**\n\n*You will need to work this out by hand and simplify the logarithm of the likelihood function.*\n`r longmcq(opts3)`\n::::\n\n`r hide(\"Solution\")`\nThe log-likelihood can be found as follows,\n\n$$\n\\begin{align}\n\\ln L(\\sigma^2|\\mathbb{x})&=\\ln\\left[\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\\right]\\\\\n&=\\ln\\left[\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right]+\\ln\\left[\\prod_{i=1}^n\\exp\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\\right]\\\\\n&=\\sum_{i=1}^n\\ln\\left[(2\\pi\\sigma^2)^{-\\frac{1}{2}}\\right]+\\sum_{i=1}^n\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\\\\\n&=-\\frac{1}{2}\\sum_{i=1}^n\\ln[2\\pi]-\\frac{1}{2}\\sum_{i=1}^n\\ln[\\sigma^2]-\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{2\\sigma^2}\\\\\n&=-\\frac{n}{2}\\ln(2\\pi)-\\frac{n}{2}\\ln(\\sigma^2)-\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{2\\sigma^2} \n\\end{align}\n$$ {#eq-normalloglike}\n\nThis is the function for which we want to find the value that maximizes it, as this will be the maximum likelihood estimator (MLE).\n`r unhide()`\n::::\n:::\n\n:::{.question}\n::::{.question-header}\nTask\n::::\n::::{.question-container}\n```{r, echo=FALSE}\nopts4 <- sample(c(answer = \"Differentiate $\\\\ln L(\\\\sigma^2|\\\\mathbb{x})$ with respect to $\\\\sigma^2$ and set equal to 0.\",\n                  \"Differentiate $\\\\ln L(\\\\sigma^2|\\\\mathbb{x})$ with respect to $\\\\mu$ and set equal to 0.\",\n                  \"Differentiate $L(\\\\sigma^2|\\\\mathbb{x})$ with respect to $\\\\sigma^2$ and set equal to 0.\",\n                  \"Differentiate $L(\\\\sigma^2|\\\\mathbb{x})$ with respect to $\\\\mu$ and set equal to 0.\"))\n```\n::::{.webex-check}\n**What is the next step required to find the value of $\\sigma^2$ that maximises $\\ln L(\\sigma^2|\\mathbb{x})$?**\n`r longmcq(opts4)`\n::::\n\n`r hide(\"Solution\")`\nThe first order derivative of the log-likelihood function ([ -@eq-normalloglike]) is given by,\n\n$$\n\\begin{align}\n\\frac{\\partial\\ln L(\\sigma^2|\\mathbb{x})}{\\partial\\sigma^2}&=-\\frac{n}{2\\sigma^2}+\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{2(\\sigma^2)^2}=0\n\\end{align}\n$$\n\nThe solution to this equation is given by $\\sigma^2=\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{n}$ (try and show this yourself). \n`r unhide()`\n::::\n:::\n\n:::{.question}\n::::{.question-header}\nTask\n::::\n::::{.question-container}\n```{r, echo=FALSE}\nopts5 <- sample(c(answer = \"Take the second order derivative of the log-likelihood function and ensure it is negative at $\\\\widehat{\\\\sigma^2}$.\",\n                  \"Take the second order derivative of the log-likelihood function and ensure it is positive at $\\\\widehat{\\\\sigma^2}$.\",\n                  \"Take the second order derivative of the likelihood function and ensure it is negative at $\\\\widehat{\\\\sigma^2}$.\",\n                  \"Take the second order derivative of the likelihood function and ensure it is positive at $\\\\widehat{\\\\sigma^2}$.\"))\n```\n::::{.webex-check}\n**What is the final step required to ensure that a maximum has been found?**\n`r longmcq(opts5)`\n::::\n`r hide(\"Solution\")`\nThe second order derivative of the log-likelihood function is,\n\n$$\n\\begin{align}\n\\frac{\\partial^2\\ln L(\\sigma^2|\\mathbb{x})}{\\partial(\\sigma^2)^2}=\\frac{n}{2(\\sigma^2)^2}-\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{(\\sigma^2)^3}\n\\end{align}\n$$\n\nThen, to ensure that a maximum of the log-likelihood function has been found, we need to show that $\\frac{\\partial^2\\ln L(\\sigma^2|\\mathbb{x})}{\\partial(\\sigma^2)^2}<0$ when $\\sigma^2=\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{n}$.\n\nThat is, we want to check that when we sub in $\\sigma^2=\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{n}$,\n\n$$\n\\begin{align}\n\\frac{\\partial^2\\ln L(\\sigma^2|\\mathbb{x})}{\\partial(\\sigma^2)^2}=\\frac{n}{2(\\sigma^2)^2}-\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{(\\sigma^2)^3}&<0\\\\\n\\frac{n\\sigma^2}{2}-\\sum_{i=1}^n(x_i-\\mu)^2&<0\\\\\n\\frac{n}{2}\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{n}-\\sum_{i=1}^n(x_i-\\mu)^2&<0\\\\\n-\\frac{1}{2}\\sum_{i=1}^n(x_i-\\mu)^2&<0\n\\end{align}\n$$\n\nwhich is true since $\\sum_{i=1}^n(x_i-\\mu)^2>0$.\n\nTherefore, the **maximum likelihood estimate** of $\\sigma^2$ is $\\widehat{\\sigma^2}(\\mathbb{x})=\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{n}$.\n`r unhide()`\n\n::::\n:::\n\n\n**Simulating a sample and it's corresponding MLE**\n\nWe can draw 1000 random samples from a $N(4, 1)$ distribution, to verify that our maximum likelihood estimator $\\widehat{\\sigma^2}(\\mathbb{x})=\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{n}$ gives a reasonably close estimate to the true parameter $\\sigma^2=1$.\n\nTo start with, draw and save the samples in the vector `x` using the code below. Here, the function `set.seed()` has been used so that the random numbers selected when `rnorm()` is used are always the same, no matter how many times the code is run. It doesn't matter what value is used inside `set.seed()`, as long as it is always the same value each time the code is run, the random values will remain the same.  If you use the value `123` as in this code, you will get the same results as shown below.\n\n::: panel-tabset\n## R Code\n```{r}\nset.seed(123)\nn <- 1000\nmu <- 4\nsigma <- 1\nx <- rnorm(n = n, mean = mu, sd = sigma)\n```\n:::\n\nIn the quiz questions above, we saw that the log-likelihood function is given by,\n\n$$\n\\ln L(\\sigma^2|\\mathbb{x})=-\\frac{n}{2}\\ln(2\\pi)-\\frac{n}{2}\\ln(\\sigma^2)-\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{2\\sigma^2}\n$$\n\nWrite a function in R called `loglike_sigma2` which will take the values in `x` and a given value for $\\sigma^2$, and return the value of $\\ln L(\\sigma^2|\\mathbb{x})$ using the code:\n\n::: panel-tabset\n## R code\n```{r}\nloglike_sigma2 <- function(sigma2){\n  -n/2*log(2*pi) - n/2*log(sigma2) - (sum((x-mu)^2))/(2*sigma2)\n}\n```\n:::\n\nCalculate the value of the maximum likelihood estimator (MLE), $\\widehat{\\sigma^2}=\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{n}$, based on the simulated data stored in `x` using:\n\n::: panel-tabset\n## R Code\n```{r}\nmle_sigma2 <- sum((x-mu)^2)/n\n```\n:::\n\nThis tells us that $\\widehat{\\sigma^2}=`r round(mle_sigma2, 3)`$, based on this observed sample.\n\nUse `ggplot2` to show a plot of the log-likelihood function ([ -@eq-normalloglike]) and add a vertical line at the maximum likelihood estimate $\\widehat{\\sigma^2}=`r round(mle_sigma2, 3)`$ using:\n\n::: panel-tabset\n## R code\n```{r, eval = FALSE}\nggplot(data.frame(x = c(0.5, 2.45)), aes(x = x)) +\n  stat_function(fun = loglike_sigma2, n = 200) +\n  labs(x = expression(sigma^2),\n       y = \"log-likelihood\") +\n  geom_vline(xintercept = mle_sigma2, lty = \"dashed\")\n```\n\n## Plots\n```{r, echo=FALSE}\nggplot(data.frame(x = c(0.5, 2.45)), aes(x = x)) +\n  stat_function(fun = loglike_sigma2, n = 200) +\n  labs(x = expression(sigma^2),\n       y = \"log-likelihood\") +\n  geom_vline(xintercept = mle_sigma2, lty = \"dashed\")\n```\n:::\n\nThe reason that this estimate is not **exactly** equal to $\\sigma^2=1$, which we used to draw the random sample, is because the maximum likelihood estimator is dependent on the sample observed. It gives us an *estimate* of the true population parameter, based on the sample. As we can see in the plot, this estimate is relatively close to the true population parameter $\\sigma^2=1$.\n\nAfter having defined the function `loglike_sigma2`, we could use the function `optimize()` to find the maximum likelihood estimate. When the code below is run, we see again that the value that maximizes this function is $\\widehat{\\sigma^2}=`r round(mle_sigma2, 3)`$ which is in agreement with what we found 'by hand'.\n\n::: panel-tabset\n## R Code\n```{r, eval=FALSE}\noptimize(f = loglike_sigma2, interval = c(0.5, 2.5), maximum = TRUE)\n```\n\n## Output\n```{r, echo=FALSE}\noptimize(f = loglike_sigma2, interval = c(0.5, 2.5), maximum = TRUE)\n```\n:::\n\nWe could also use the `nlm()` function to find the value that maximizes the log-likelihood function, but remember this actually only finds *minimum* values of a given function, so we first have to define the negative of the log-likelihood function, `negloglike_sigma2`.\n\n::: panel-tabset\n## R Code\n```{r}\nnegloglike_sigma2 <- function(sigma2){\n  (-1)*loglike_sigma2(sigma2)\n}\n```\n\n```{r, eval=FALSE, warning=FALSE}\nnlm(f = negloglike_sigma2, p = 0.5)$estimate\n```\n\n## Output\n```{r, echo=FALSE, warning=FALSE}\nnlm(f = negloglike_sigma2, p = 0.5)$estimate\n```\n:::\n\nThis again shows us that the value that maximizes of the log-likelihood function ([ -@eq-normalloglike]) is $\\widehat{\\sigma^2}=`r round(mle_sigma2, 3)`$, based on our observed sample.\n\n---\n\nYou can find more examples of finding maximum likelihood estimators, both 'by hand' and using R in [Section 7.3.2 Likelihood and Maximum Likelihood Estimators](https://read.kortext.com/reader/pdf/92741/419){target=\"_blank\"} of *Probability and Statistics with R*.\n\n\n\n\n\n\n\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css","include/webex.css"],"toc":true,"include-after-body":["include/webex.js"],"embed-resources":true,"output-file":"normal.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.553","editor":"source","theme":["cosmo","custom.scss"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}